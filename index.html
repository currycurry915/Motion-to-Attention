<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>AttentionFlow: Text-to-Video Editing Using Motion Map Injection Module</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">AttentionFlow: Text-to-Video Editing Using Motion Map Injection Module</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">First Author</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Second Author</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Third Author</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Institution Name<br>Conferance name and year</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="static/pdfs/920.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/920_supple.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://anonymous.4open.science/r/AttentionFlow-197C" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


        
<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img class="center-img" src="static/prompt/label.png", width="100%", style="padding-top: 2%;">
        <img class="center-img" src="static/images/clouds_waves_input.gif", width="33.3%", style="padding-top: 2%;">
        <img class="center-img" src="static/images/clouds_waves_ori.gif", width="33.3%">
        <img class="center-img" src="static/images/clouds_waves_MMI.gif", width="33.3%">
        <img class="center-img" src="static/prompt/waves_re.png", width="100%">
      </div>
      <div class="item">
        <!-- Your image here -->
        <img class="center-img" src="static/prompt/label.png", width="100%", style="padding-top: 2%;">
        <img class="center-img" src="static/images/bubble_duck_input.gif", width="33.3%", style="padding-top: 2%;">
        <img class="center-img" src="static/images/bubble_duck_ori.gif", width="33.3%">
        <img class="center-img" src="static/images/bubble_duck_MMI.gif", width="33.3%">
        <img class="center-img" src="static/prompt/duck_re.png", width="100%">
      </div>
     <div class="item">
      <!-- Your image here -->
       <img class="center-img" src="static/prompt/label.png", width="100%", style="padding-top: 2%;">
      <img class="center-img" src="static/images/colorful_water_input.gif", width="33.3%", style="padding-top: 2%;">
      <img class="center-img" src="static/images/colorful_water_ori.gif", width="33.3%">
      <img class="center-img" src="static/images/colorful_water_MMI.gif", width="33.3%">
      <img class="center-img" src="static/prompt/colorful_re.png", width="100%">
    </div>
    <div class="item">
      <!-- Your image here -->
       <img class="center-img" src="static/prompt/label.png", width="100%", style="padding-top: 2%;">
      <img class="center-img" src="static/images/red_car_input.gif", width="33.3%", style="padding-top: 2%;">
      <img class="center-img" src="static/images/red_car_ori.gif", width="33.3%">
      <img class="center-img" src="static/images/red_car_MMI.gif", width="33.3%">
      <img class="center-img" src="static/prompt/red_car_re.png", width="100%">
    </div>
    <div class="item">
      <!-- Your image here -->
       <img class="center-img" src="static/prompt/label.png", width="100%", style="padding-top: 2%;">
      <img class="center-img" src="static/images/balloon_input.gif", width="33.3%", style="padding-top: 2%;">
      <img class="center-img" src="static/images/balloon_ori.gif", width="33.3%">
      <img class="center-img" src="static/images/balloon_MMI.gif", width="33.3%">
      <img class="center-img" src="static/prompt/balloon.png", width="100%">
    </div>    
    <div class="item">
      <!-- vid2vid windmill -->
       <img class="center-img" src="static/images/label_vid2vid.png", width="100%", style="padding-top: 2%;">
      <img class="center-img" src="static/images/yellow_windmill_input.gif", width="33.3%", style="padding-top: 2%;">
      <img class="center-img" src="static/images/vid2vid_windmill_ori.gif", width="33.3%">
      <img class="center-img" src="static/images/vid2vid_windmill_MMI.gif", width="33.3%">
      <img class="center-img" src="static/prompt/pink_windmill_re.png", width="100%">
    </div>    
    <div class="item">
      <!-- vid2vid lava -->
       <img class="center-img" src="static/images/label_vid2vid.png", width="100%", style="padding-top: 2%;">
      <img class="center-img" src="static/images/clouds_lava_input.gif", width="33.3%", style="padding-top: 2%;">
      <img class="center-img" src="static/images/vid2vid_lava_ori.gif", width="33.3%">
      <img class="center-img" src="static/images/vid2vid_lava_MMI.gif", width="33.3%">
      <img class="center-img" src="static/prompt/lava_re.png", width="100%">      
    </div>
    <div class="item">
      <!-- FateZero beer -->
       <img class="center-img" src="static/images/label_fatezero.png", width="100%", style="padding-top: 2%;">
      <img class="center-img" src="static/images/beer_input.gif", width="33.3%", style="padding-top: 2%;">
      <img class="center-img" src="static/images/fatezero_beer_ori.gif", width="33.3%">
      <img class="center-img" src="static/images/fatezero_beer_MMI.gif", width="33.3%">
      <img class="center-img" src="static/prompt/beer.png", width="100%">      
    </div>
    <div class="item">
      <!-- FateZero fireman -->
       <img class="center-img" src="static/images/label_fatezero.png", width="100%", style="padding-top: 2%;">
      <img class="center-img" src="static/images/fatezero_fire_input.gif", width="33.3%", style="padding-top: 2%;">
      <img class="center-img" src="static/images/fatezero_fire_ori.gif", width="33.3%">
      <img class="center-img" src="static/images/fatezero_fire_MMI.gif", width="33.3%">
      <img class="center-img" src="static/prompt/fireman.png", width="100%">      
    </div>
  </div>
</div>
<br>
<h2 class="subtitle has-text-centered">
  <span style="color:#FF0000">Red words</span> indicate the prompt that Prompt-to-prompt editing is applied ('replace' or 'refine'), <br>
  <span style="color:#00B0F0">Blue words</span> indicate the prompt that Attention Flow with Motion Map Injection module is applied.
</h2>
</div>
</section>
<!-- End image carousel -->

<br>
<br>  
<br>
<br>

<!--    Our Contribution    -->  
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-justified">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Our Contribution</h2>
      </div>
      <h2 class="subtitle">
        Our proposed Motion Map Injection (MMI) module gives a way to effectively inject motion extracted from video into the attention map of the prompt. We found that editing a video with the motion extracted from the video improves general editing performance and enables selective editing according to the direction in which the object moves.
      </h2>
    </div>
  </div>
</section>

<!--    contribution     -->  
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-justified">
      <!--
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Framework</h2>
      </div> -->
      <img class="center-img" src="static/images/intro.jpg"/>
      <h2 class="subtitle">
        Comparison of video editing output and attention map compared to existing methods. Both Image-P2P and Video-P2P
failed to accurately estimate the attention map, resulting in discrepancy with the prompt. Our framework performed realistic video
editing by enabling accurate attention maps through optical flow guided attention maps. Following figure describes our proposed method.
      </h2>
    </div>
  </div>
</section>  
  
<br>
<br>


<!--    Abstract    -->  
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-justified">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Abstract</h2>
      </div>
      <h2 class="subtitle">
        Text-guided video editing studies have recently increased due to the impressive performance of text-to-image diffusion models. 
        Existing research on video editing has introduced an implicit method for estimating inter-frame attention from cross-frame attention, 
        which produces videos that are temporally consistent. However, as these techniques rely on generative models trained on text-image pair data, 
        they are unable to handle motion, which is a special feature of video. When a video is edited by manipulating prompts, 
        the attention map of the prompt that implies the motion of the video (such as “running” or “moving”) is likely to be inaccurately estimated, 
        which results in errors in video editing. In this article, we suggest the “Motion Map Injection” (MMI) module to carry out precise video editing 
        by explicitly taking motion into account. The MMI module offers a basic but efficient way to provide text-to-video (T2V) model with the video motion information.
      </h2>
    </div>
  </div>
</section>
  
<br>
<br>  
<br>
<br>
  
  
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-justified">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Framework</h2>
      </div>
      <img class="center-img" src="static/images/fig2-last.png" />
      <h2 class="subtitle">
        Overall framework of this study. 
        First, the T2V-Model generates an attention map by receiving video and prompts as input. 
        At the same time, the Motion Map Injection module receives the video frame, generates a motion map, and injects it into the attention map of the T2V-Model. 
        After that, text-to-video editing is performed using the attention map that includes video motion information.
      </h2>
    </div>
  </div>
</section>
  
<br>
<br>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-justified">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Qualitative Results</h2>
      </div>
        <h2 class="subtitle">
          We coducted extensive exprements on existing T2V models (vid2vid-zero, FateZero) including Video-P2P.
          Followings are those expermental results.
        </h2>
    </div>
  </div>
</section>
  
  
<section class="hero is-small">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-justified">
      <img class="center-img" src="static/images/f_clouds_waves.png" width="100%" />
      <br> 
      <br> 
      <img class="center-img" src="static/images/f_duck.png" width="100%" />
      <br>  
      <br>
      <img class="center-img" src="static/images/f_colorful.png" width="100%" />
      <br>
      <br>
      <img class="center-img" src="static/images/f_red_car.png" width="100%" />
      <br>
      <br>
      <img class="center-img" src="static/images/f_smoke.png" width="100%" />
      <br>
      <br>
      <img class="center-img" src="static/images/f_vid2vid_windmill.png" width="100%" />
      <br>
      <br>
      <img class="center-img" src="static/images/f_vid2vid_lava.png" width="100%" />
      <br>
      <br>
      <img class="center-img" src="static/images/f_fatezero_beer.png" width="100%" />
      <br>
      <br>
      <img class="center-img" src="static/images/f_fatezero_fireman.png" width="100%" />
      <br>
      <br>
    </div>
  </div>
</section>

<!-- 회색 박스 가능? -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <img class="center-img" src="static/images/f_smoke.png" width="100%" />
        </div>
      </div>
    </div>
  </div>
</section>
  
<br>
<br>
<br>
<br>

<!--    Direction application     -->  
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-justified">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Application</h2>
      </div>
      <img class="center-img" src="static/images/f_pink_train.png"/>
      <h2 class="subtitle">
        Since optical flow has the information on direction of pixel movement, as well as magnitude, 
        our model can be applied to allow the user to edit contents in a specific direction by rotating the optical flow 
        according to the direction provided by the user before injecting it.
      </h2>
    </div>
  </div>
</section>  

<br>
<br>
<br>
<br>

<!--    Ablation Study    -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-justified">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Ablation Study</h2>
      </div>
      <!-- 잠시 주석 : alt="" 지움, 33%로 바꿈 / 텍스트도 넣어지나?
      <img class="center-img" src="static/images/ncc.png"/> -->
      <br>
      <figure>
        <img src="static/images/TM_SQDIFF.gif" width='33%'>
        <img src="static/images/TM_CCORR.gif" width='33%'>
        <img src="static/images/TM_CCOEFF.gif" width='33%'>
        <figcaption>From the left, the result from applying cv2.TM_SQDIFF, cv2.TM_CCORR, and cv2.TM_CCOEFF as correlation calculating method. </figcaption>
      </figure>
      <br>
      <figure>
        <img src="static/images/TM_SQDIFF_NORMED.gif" width='33%'>
        <img src="static/images/TM_CCORR_NORMED.gif" width='33%'>
        <img src="static/images/clouds_waves_MMI.gif" width='33%'>
        <figcaption>From the left, the result from applying cv2.TM_SQDIFF_NORMED cv2.TM_CCORR_NORMED cv2.TM_CCOEFF_NORMED as correlation calculating method. </figcaption>
      </figure>
      <br>

      <h2 class="subtitle">
        Ablation study on which method for calculating correlation between attention maps and motion map makes video edited in best quality. We used cv2.TM_CCOEFF_NORMED to calculate the correlation for realistic video editing.
      </h2>
    </div>
  </div>
</section>


<br>
<br>
<br>
<br>

<!--    Followup Works    -->  
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-justified">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Followup Works</h2>
      </div>
      <h2 class="subtitle">
        We used <a href="https://video-p2p.github.io/">Video-P2P: Video Editing with Cross-attention Control</a> model as base-model which is based on Text-to-Image diffusion.
        And we expanded experments to show that our module is generally suitable for other T2V models, 
        <a href="https://github.com/baaivision/vid2vid-zero">vid2vid</a> and <a href="https://fate-zero-edit.github.io/">FateZero</a>.
      </h2>
    </div>
  </div>
</section>

<br> 
<br> 


<!--    BibTex    -->  
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-justified">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">BibTex</h2>
      </div>
      <h2 class="subtitle">
        @article{2023attentionflow,<br>
          &nbsp;&nbsp;&nbsp;&nbsp;title={AttentionFlow: Text-to-Video Editing Using Motion Map Injection Module},<br>
          &nbsp;&nbsp;&nbsp;&nbsp;year={2023}<br>
          }
      </h2>
    </div>
  </div>
</section>


  </body>
  </html>
